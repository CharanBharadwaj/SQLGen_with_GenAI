{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "213b3330-abf5-4ee3-a146-8bf50d25c570",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x11116c4d0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import random\n",
    "\n",
    "random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "#torch.set_default_device('mps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84cb1ba2-e6a4-4c07-a664-242ca7955e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "!export PYTORCH_ENABLE_MPS_FALLBACK=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9edbbefa-d370-4be7-836a-181b62c3bc6c",
   "metadata": {},
   "source": [
    "### Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "347e903c-6bbb-42f6-a3ca-52ed0172e710",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc913e81f3734e35bd1f55fe797a522c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "# model_path = \"microsoft/Phi-3-mini-4k-instruct\"\n",
    "model_path = \"mistralai/Mistral-7B-Instruct-v0.1\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path, legacy=True, use_fast=True, add_eos_token=True, max_length=250)\n",
    "tokenizer.padding_side = 'right'\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_path,\n",
    "    torch_dtype=\"auto\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e60b6d-8522-4698-b096-09ff88e0a559",
   "metadata": {},
   "source": [
    "### Model Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "829bca2e-30b1-46dc-b775-ad58522dfc68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chabhara/miniforge3/envs/DSE/lib/python3.8/site-packages/bitsandbytes/cextension.py:34: UserWarning: The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
      "  warn(\"The installed version of bitsandbytes was compiled without GPU support. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'cadam32bit_grad_fp32'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PeftModel(\n",
       "  (base_model): LoraModel(\n",
       "    (model): MistralForCausalLM(\n",
       "      (model): MistralModel(\n",
       "        (embed_tokens): Embedding(32000, 4096)\n",
       "        (layers): ModuleList(\n",
       "          (0-31): 32 x MistralDecoderLayer(\n",
       "            (self_attn): MistralSdpaAttention(\n",
       "              (q_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (mistral7Bv01-results/checkpoint-100): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (mistral7Bv01-results/checkpoint-100): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (mistral7Bv01-results/checkpoint-100): Linear(in_features=16, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (k_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (mistral7Bv01-results/checkpoint-100): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (mistral7Bv01-results/checkpoint-100): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (mistral7Bv01-results/checkpoint-100): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (v_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (mistral7Bv01-results/checkpoint-100): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (mistral7Bv01-results/checkpoint-100): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (mistral7Bv01-results/checkpoint-100): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (o_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (mistral7Bv01-results/checkpoint-100): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (mistral7Bv01-results/checkpoint-100): Linear(in_features=4096, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (mistral7Bv01-results/checkpoint-100): Linear(in_features=16, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (rotary_emb): MistralRotaryEmbedding()\n",
       "            )\n",
       "            (mlp): MistralMLP(\n",
       "              (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "              (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "              (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): MistralRMSNorm((4096,), eps=1e-05)\n",
       "            (post_attention_layernorm): MistralRMSNorm((4096,), eps=1e-05)\n",
       "          )\n",
       "        )\n",
       "        (norm): MistralRMSNorm((4096,), eps=1e-05)\n",
       "      )\n",
       "      (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from peft import LoraConfig, PeftModel\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.05,\n",
    "    bias='none',\n",
    "    task_type='CAUSAL_LM',\n",
    "    target_modules=[\n",
    "          'q_proj',\n",
    "          'k_proj',\n",
    "          'v_proj',\n",
    "          'o_proj'\n",
    "        ]\n",
    ")\n",
    "\n",
    "model = PeftModel(base_model, lora_config, \"mistral7Bv01-results/checkpoint-100\")\n",
    "\n",
    "device = torch.device(\"mps\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964b753b-6f5f-4079-88c1-223088d65170",
   "metadata": {},
   "source": [
    "### Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "46b8cb4b-67b0-4b2d-9ef4-c8597cd74983",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['answer', 'question', 'context'],\n",
       "        num_rows: 78577\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "dataset = load_dataset(\"b-mc2/sql-create-context\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e715d7-9257-43a9-a8d7-4f8511d4e5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset['train'].to_pandas().head(50).to_html()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d686b06-4296-4f81-9b61-643ce355e5d5",
   "metadata": {},
   "source": [
    "### Preprocess dataset for the need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "244aa3c8-4145-4a89-b6f5-3a87ecfd050a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['answer', 'question', 'context', 'inputs'],\n",
      "        num_rows: 78577\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "def create_prompt(sample):\n",
    "    prompt_template = PromptTemplate.from_template(\"\"\"Generate an SQL query using the following database schema:\n",
    "{database_schema}, to answer the following question:\n",
    "{user_question}.\n",
    "Response: <s>{user_response}</s>\"\"\")\n",
    "    user_message = sample['question']\n",
    "    user_response = sample['answer']\n",
    "    database_schema = sample['context']\n",
    "\n",
    "    template = prompt_template.format(database_schema=database_schema,user_question=user_message,user_response=user_response)\n",
    "    return {\"inputs\":template}\n",
    "\n",
    "\n",
    "instruct_tune_dataset = dataset.map(create_prompt)\n",
    "print(instruct_tune_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db5a272a-58b1-46a9-98ff-c66a6f1cc32f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# test = {\n",
    "#     \"question\": \"How many heads of the departments are older than 56 ?\",\n",
    "#     \"answer\" : \"SELECT COUNT(*) FROM head WHERE age > 56\",\n",
    "#     \"context\" : \"CREATE TABLE head (age INTEGER)\"\n",
    "# }\n",
    "# create_prompt(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "82889e8c-48ba-42e4-84a8-440d4af02b88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answer</th>\n",
       "      <th>question</th>\n",
       "      <th>context</th>\n",
       "      <th>inputs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SELECT COUNT(*) FROM head WHERE age &gt; 56</td>\n",
       "      <td>How many heads of the departments are older th...</td>\n",
       "      <td>CREATE TABLE head (age INTEGER)</td>\n",
       "      <td>Generate an SQL query using the following data...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SELECT name, born_state, age FROM head ORDER B...</td>\n",
       "      <td>List the name, born state and age of the heads...</td>\n",
       "      <td>CREATE TABLE head (name VARCHAR, born_state VA...</td>\n",
       "      <td>Generate an SQL query using the following data...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SELECT creation, name, budget_in_billions FROM...</td>\n",
       "      <td>List the creation year, name and budget of eac...</td>\n",
       "      <td>CREATE TABLE department (creation VARCHAR, nam...</td>\n",
       "      <td>Generate an SQL query using the following data...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SELECT MAX(budget_in_billions), MIN(budget_in_...</td>\n",
       "      <td>What are the maximum and minimum budget of the...</td>\n",
       "      <td>CREATE TABLE department (budget_in_billions IN...</td>\n",
       "      <td>Generate an SQL query using the following data...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SELECT AVG(num_employees) FROM department WHER...</td>\n",
       "      <td>What is the average number of employees of the...</td>\n",
       "      <td>CREATE TABLE department (num_employees INTEGER...</td>\n",
       "      <td>Generate an SQL query using the following data...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              answer  \\\n",
       "0           SELECT COUNT(*) FROM head WHERE age > 56   \n",
       "1  SELECT name, born_state, age FROM head ORDER B...   \n",
       "2  SELECT creation, name, budget_in_billions FROM...   \n",
       "3  SELECT MAX(budget_in_billions), MIN(budget_in_...   \n",
       "4  SELECT AVG(num_employees) FROM department WHER...   \n",
       "\n",
       "                                            question  \\\n",
       "0  How many heads of the departments are older th...   \n",
       "1  List the name, born state and age of the heads...   \n",
       "2  List the creation year, name and budget of eac...   \n",
       "3  What are the maximum and minimum budget of the...   \n",
       "4  What is the average number of employees of the...   \n",
       "\n",
       "                                             context  \\\n",
       "0                    CREATE TABLE head (age INTEGER)   \n",
       "1  CREATE TABLE head (name VARCHAR, born_state VA...   \n",
       "2  CREATE TABLE department (creation VARCHAR, nam...   \n",
       "3  CREATE TABLE department (budget_in_billions IN...   \n",
       "4  CREATE TABLE department (num_employees INTEGER...   \n",
       "\n",
       "                                              inputs  \n",
       "0  Generate an SQL query using the following data...  \n",
       "1  Generate an SQL query using the following data...  \n",
       "2  Generate an SQL query using the following data...  \n",
       "3  Generate an SQL query using the following data...  \n",
       "4  Generate an SQL query using the following data...  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instruct_tune_dataset['train'].to_pandas().head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dfbe9a3c-09b5-4526-aff6-c981beb37e34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['inputs'],\n",
       "        num_rows: 78577\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = instruct_tune_dataset.map(batched=True,remove_columns=['answer', 'question', 'context'])\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ac109ae-8e1b-4f84-afea-316191e48fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PYTORCH_MPS_HIGH_WATERMARK_RATIO\"] = \"0.9\"\n",
    "os.environ[\"PYTORCH_ENABLE_MPS_FALLBACK\"] = \"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c000f61a-3661-45c2-adcc-505a3992611f",
   "metadata": {},
   "source": [
    "### Training Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd4cd55f-0f13-4607-acd6-0a0a3609e837",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./mistral7Bv01-results',\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=1,\n",
    "    auto_find_batch_size = True,\n",
    "    #per_device_train_batch_size=4,\n",
    "    # optim = \"paged_adamw_32bit\",\n",
    "    gradient_accumulation_steps=1,\n",
    "    lr_scheduler_type = \"cosine\",\n",
    "    warmup_ratio = 0.03,\n",
    "    #eval_strategy='no',\n",
    "    save_strategy='steps',\n",
    "    learning_rate=3e-4,\n",
    "    eval_strategy = \"steps\",\n",
    "    prediction_loss_only = True,\n",
    "    bf16=True,\n",
    "    max_steps=100,\n",
    "    #warmup_steps=50,\n",
    "    seed=42,\n",
    "    #eval_steps=50\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64d10b3-c10f-4e80-a2fb-b20dda7bf959",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "06aa6c38-b14c-48a1-832e-f78382dd18ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-09-14 21:07:50,619] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to mps (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0914 21:07:51.069116 8194789184 torch/distributed/elastic/multiprocessing/redirects.py:27] NOTE: Redirects are currently not supported in Windows or MacOs.\n",
      "/Users/chabhara/miniforge3/envs/DSE/lib/python3.8/site-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': dataset_text_field, max_seq_length. Will not be supported from version '1.0.0'.\n",
      "\n",
      "Deprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/Users/chabhara/miniforge3/envs/DSE/lib/python3.8/site-packages/trl/trainer/sft_trainer.py:280: UserWarning: You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
      "  warnings.warn(\n",
      "/Users/chabhara/miniforge3/envs/DSE/lib/python3.8/site-packages/trl/trainer/sft_trainer.py:318: UserWarning: You passed a `dataset_text_field` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
      "  warnings.warn(\n",
      "max_steps is given, it will override any value given in num_train_epochs\n"
     ]
    }
   ],
   "source": [
    "from transformers import DataCollatorForLanguageModeling\n",
    "from trl import SFTTrainer\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "            model=model,\n",
    "            train_dataset=train_dataset[\"train\"],\n",
    "            #eval_dataset=dataset['test'],\n",
    "            dataset_text_field=\"inputs\",\n",
    "            tokenizer=tokenizer,\n",
    "            args=training_args,\n",
    "            packing=False,\n",
    "            max_seq_length=500\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c1d26e62-6917-4671-a435-1f2f689128c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [100/100 2:12:30, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=100, training_loss=0.9979658508300782, metrics={'train_runtime': 7963.5804, 'train_samples_per_second': 0.1, 'train_steps_per_second': 0.013, 'total_flos': 4406573824868352.0, 'train_loss': 0.9979658508300782, 'epoch': 0.010180189351521938})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5e88688-b2b2-4b4d-8be1-718527cf4b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prompt_for_test(sample):\n",
    "    prompt_template = PromptTemplate.from_template(\"\"\"Generate an SQL query using the following database schema:\n",
    "{database_schema}, to answer the following question:\n",
    "{user_question}. Also, suggest a chart type best suited to plot the data generated by the query.\n",
    "Response:\"\"\")\n",
    "    user_message = sample['question']\n",
    "    #user_response = sample['answer']\n",
    "    database_schema = sample['context']\n",
    "\n",
    "    template = prompt_template.format(database_schema=database_schema,user_question=user_message)\n",
    "    return template"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bbd97df-84b7-4e36-8a68-548b422b179c",
   "metadata": {},
   "source": [
    "---\n",
    "### Output\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b3b6b5d-9d6f-42cc-ab42-b674e7d37fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from builtins import input\n",
    "\n",
    "#question = input(\"Please enter your query:Start your query likeGenerate an SQL query to retrieve...\")\n",
    "question = \"How many days had both mean humidity above 50 and mean visibility above 8?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fbe9d65d-cea5-4e10-9eda-c8f4519bf568",
   "metadata": {},
   "outputs": [],
   "source": [
    "#database_schema = input(\"Please enter database schema:CREATE TABLE tablename (columns <datatype)\")\n",
    "database_schema = \"CREATE TABLE weather (mean_humidity VARCHAR, mean_visibility_miles VARCHAR)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7b7bb1b3-4b30-408f-ac64-11760cab23ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2a9bd551-23de-484a-8ca1-7848565ef799",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_query = {\n",
    "    \"question\": question,\n",
    "    \"context\" : database_schema\n",
    "}\n",
    "\n",
    "\n",
    "model_inputs = tokenizer(create_prompt_for_test(test_query), return_tensors=\"pt\").to(\"mps:0\")\n",
    "\n",
    "output = model.generate(**model_inputs, max_length=500, no_repeat_ngram_size=30, pad_token_id=tokenizer.eos_token_id, eos_token_id=tokenizer.eos_token_id)[0]\n",
    "\n",
    "result = tokenizer.decode(output, skip_special_tokens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "032550df-00b6-4da8-9e86-8612d19620cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       " Generate an SQL query using the following database schema:\n",
       "CREATE TABLE weather (mean_humidity VARCHAR, mean_visibility_miles VARCHAR), to answer the following question:\n",
       "How many days had both mean humidity above 50 and mean visibility above 8?. Also, suggest a chart type best suited to plot the data generated by the query.\n",
       "Response:\n",
       "```\n",
       "SELECT COUNT(*) AS days\n",
       "FROM weather\n",
       "WHERE mean_humidity > '50' AND mean_visibility_miles > '8'\n",
       "```\n",
       "The best chart type to plot the data generated by this query would be a line chart, as it would allow for easy visualization of the trend in the number of days with both mean humidity above 50 and mean visibility above 8 over time."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "result = result.replace('<s>','').replace('</s>','')\n",
    "display(Markdown(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878af119-16ad-4596-8584-cb8b0afd76f0",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
